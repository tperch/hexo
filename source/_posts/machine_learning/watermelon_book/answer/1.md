---
title: "《机器学习》 西瓜书习题 第 1 章: 绪论"
tags:  # 标签
- 机器学习
- 西瓜书
- 习题
categories:  # 分类
- [机器学习, 西瓜书, 习题]
mathjax: true
date: 2020-02-26 17:10:00
cover: https://cdn.jsdelivr.net/gh/yunwanjia-cloud/blog/machine_learning/watermelon_book/answer/1/1.png
---
　　《机器学习》 西瓜书的课后习题参考答案.
<!-- more -->
#习题
## 1.1
　　**表 $$\,1.1\,$$ 中若只包含编号为 $$\,1\,$$ 和 $$\,4\,$$ 的两个样例, 试给出相应的版本空间.**

　　这应该不难理解吧，直接上表格.

|编号|色泽|根蒂|敲声|好瓜|
|:-:|:-:|:-:|:-:|:-:|
| $$\,1\,$$ |青绿|蜷缩|浊响| 是 |
| $$\,4\,$$ |乌黑|稍蜷|沉闷| 否 |


## 1.2
　　**与使用单个合取式来进行假设表示相比, 使用 "析合范式" 将使得假设空间具有更强的表示能力. 例如**
$$好瓜 \leftrightarrow \big((色泽=*)\wedge(根蒂=蜷缩)\wedge(敲声=*)\big)\vee\big((色泽=乌黑)\wedge(根蒂=*)\wedge(敲声=沉闷)\big)$$
**会把 "$$\,(色泽=*)\wedge(根蒂=蜷缩)\wedge(敲声=*)\,$$" 以及 "$$\,(色泽=乌黑)\wedge(根蒂=*)\wedge(敲声=沉闷)\,$$" 都分类为 "好瓜" . 若使用最多包含 $$\,k\,$$ 个合取式的析合范式来表达 $$\,1.1\,$$ 西瓜分类问题的假设空间, 试估算共有多少种可能的假设.**

　　一共有 $$\,3\,$$ 个特征, 第一个特征有 $$\,3\,$$  种取值(算上 $$\,*\,$$ ), 第二, 三个都是 $$\,4\,$$ 种取值.
　　每个合取式我们分为三项:色泽, 根蒂, 敲声.这里要注意某个项其实是可以同时选择两种取值的, 比如色泽这一项可以是 $$\,\big((色泽=青绿)\wedge(色泽=乌黑)\big)\,$$ 而不是只能有一个取值.
　　那么第一项只可能选择一个或两个取值, 取值是一个时有 $$\,3\,$$ 种可能, 取值为两种时只有 $$\,1\,$$ 种可能(即除了 $$\,*\,$$ 外的另两种一起取到),  其他项以此类推, 那么就有 $$\,4\times7\times7=196\,$$ 种合取式, 因此 $$\,k_{ma\boldsymbol{x}}=196\,$$. 
　　所以可能的假设总数为 $$\,\sum^{k_{ma\boldsymbol{x}}}_{i=1}C_{k_{ma\boldsymbol{x}}}^i\,$$ , 即任意取 $$\,1\sim k_{ma\boldsymbol{x}}\,$$个合取式然后组合成的析合范式的数量.
　　当然我们这里不考虑冗余 ~~(因为我懒)~~ .

## 1.3
　　**若数据包含噪声, 则假设空间中有可能不存在与所有训练样本都一致的假设. 在此情形下, 试设计一种归纳偏好用于假设选择.**

　　当然是奥卡姆剃刀啦, "如无必要, 勿增实体", 大概体现了一种哲学思想吧.

## 1.4*

　　**本章 $$\,1.4\,$$ 节在论述 "没有免费的午餐" 定理时, 默认使用了 "分类错误率" 作为性能度量来对分类器进行评估. 若换用其他性能度量 $$\,\ell\,$$ ,则将式$$\,(1.1)\,$$改为**
$$E_{ote}(\mathfrak{L}_a\mid X,f)=\sum_h\sum_{\boldsymbol{\boldsymbol{x}}\in \mathcal{X}-X}P(\boldsymbol{\boldsymbol{x}})\ell(h(\boldsymbol{\boldsymbol{x}}),f(\boldsymbol{\boldsymbol{x}}))P(h\mid X,\mathfrak{L}_a)$$
**试证明 "没有免费的午餐定理" 仍成立.**

　　其实和原来的推导差不多. 对所有可能的 $$\,f\,$$ 按均匀发布对误差求和, 有
$$\begin{aligned}
\sum_fE_{ote}(\mathfrak{L}_a\mid X,f)&=\sum_f\sum_h\sum_{\boldsymbol{x}\in \mathcal{X}-X}P(\boldsymbol{x})\ell(h(\boldsymbol{x}),f(\boldsymbol{x}))P(h\mid X,\mathfrak{L}_a)\\
&=\sum_{\boldsymbol{x}\in\mathcal{X}-X}P(\boldsymbol{x})\sum_hp(h\mid X,\mathfrak{L})\sum_f\ell(h(\boldsymbol{x}),f(\boldsymbol{x}))\\
&=\sum_{\boldsymbol{x}\in\mathcal{X}-X}P(\boldsymbol{x})\sum_hp(h\mid X,\mathfrak{L})E(\ell)\\
&=E(\ell)\sum_{\boldsymbol{x}\in\mathcal{X}-X}P(\boldsymbol{x})\sum_hp(h\mid X,\mathfrak{L})\\
&=E(\ell)\sum_{\boldsymbol{x}\in\mathcal{X}-X}P(\boldsymbol{x})\cdot1\\
&=E(\ell)\sum_{\boldsymbol{x}\in\mathcal{X}-X}P(\boldsymbol{x})
\end{aligned}$$
　　$$\,E(\ell)\,$$ 为 $$\,\ell\,$$ 的数学期望(就是 $$\,\ell\,$$ 这个函数所有可能输出的均值去乘 $$\,2^{|\mathcal{X}|}\,$$, 因为 $$\,f\,$$ 是任意的. ~~反正是个常数.~~).
　　最终表达式与学习算法 $$\,\mathfrak{L}\,$$ 无关, 于是$$\sum_fE_{ate}(\mathfrak{L}\mid X,f)=\sum_fE_{ate}(\mathfrak{L}\mid X,f)$$
　　所以 "没有免费的午餐定理" 仍成立.

## 1.5
　　**试述机器学习能在互联网搜索的哪些环节起什么作用.**

　　这个就多了, 比如搜索引擎, 图片搜索, 智能化推荐, 还有很多很多. 当然你还可以用机器学习来破解反爬虫, 比如识别简单的验证码.